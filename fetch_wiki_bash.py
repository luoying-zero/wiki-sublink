#!/usr/bin/env python3
"""
æŠ“å– GitHub Wiki ä¸­çš„ Bash ä»£ç æ®µ
æ’é™¤ä»¥æŒ‡å®šå‰ç¼€å¼€å¤´çš„ä»£ç æ®µ
"""

import json
import os
import re
import requests
from datetime import datetime
from pathlib import Path


def load_config(config_path="wiki_sources.json"):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, "r", encoding="utf-8") as f:
        return json.load(f)


def fetch_wiki_page(repo: str, page: str, token: str = None) -> str:
    """
    è·å– GitLab Wiki é¡µé¢çš„åŸå§‹ Markdown å†…å®¹
    
    GitLab Wiki API æ ¼å¼:
    https://gitlab.com/api/v4/projects/{project_id}/wikis/{slug}
    
    æˆ–ç›´æ¥è®¿é—® raw å†…å®¹:
    https://gitlab.com/{namespace}/{project}/-/wikis/{page}/raw
    """
    # URL ç¼–ç é¡¹ç›®è·¯å¾„ (namespace/project -> namespace%2Fproject)
    encoded_repo = repo.replace("/", "%2F")
    
    # å¤„ç†é¡µé¢åç§°ï¼ˆç©ºæ ¼è½¬æ¢ä¸ºè¿å­—ç¬¦æˆ–ä¿æŒåŸæ ·ï¼‰
    page_slug = page.replace(" ", "-")
    
    headers = {}
    if token:
        headers["PRIVATE-TOKEN"] = token
    
    # å°è¯•å¤šç§ URL æ ¼å¼
    urls = [
        # GitLab API æ–¹å¼
        f"https://gitlab.com/api/v4/projects/{encoded_repo}/wikis/{page_slug}",
        f"https://gitlab.com/api/v4/projects/{encoded_repo}/wikis/{page}",
        # Raw å†…å®¹æ–¹å¼
        f"https://gitlab.com/{repo}/-/wikis/{page_slug}/raw",
        f"https://gitlab.com/{repo}/-/wikis/{page}/raw",
    ]
    
    for url in urls:
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code == 200:
                print(f"âœ“ æˆåŠŸè·å–: {repo}/wiki/{page}")
                
                # API è¿”å› JSONï¼Œéœ€è¦æå– content å­—æ®µ
                if "/api/v4/" in url:
                    data = response.json()
                    return data.get("content", "")
                else:
                    return response.text
        except requests.RequestException as e:
            print(f"âœ— è¯·æ±‚å¤±è´¥ {url}: {e}")
            continue
    
    print(f"âœ— æ— æ³•è·å–: {repo}/wiki/{page}")
    return None


def extract_bash_code_blocks(markdown_content: str, exclude_prefixes: list) -> list:
    """
    ä» Markdown å†…å®¹ä¸­æå– Bash ä»£ç æ®µ
    æ’é™¤ä»¥æŒ‡å®šå‰ç¼€å¼€å¤´çš„ä»£ç æ®µ
    
    æ”¯æŒçš„æ ¼å¼:
    ```bash
    code here
    ```
    
    ```sh
    code here
    ```
    
    ```shell
    code here
    ```
    """
    # åŒ¹é… bash/sh/shell ä»£ç å—
    pattern = r'```(?:bash|sh|shell)\s*\n(.*?)```'
    matches = re.findall(pattern, markdown_content, re.DOTALL | re.IGNORECASE)
    
    filtered_blocks = []
    for block in matches:
        block = block.strip()
        
        # æ£€æŸ¥æ˜¯å¦ä»¥æ’é™¤çš„å‰ç¼€å¼€å¤´
        should_exclude = False
        for prefix in exclude_prefixes:
            if block.lower().startswith(prefix.lower()):
                should_exclude = True
                print(f"  âŠ˜ æ’é™¤ä»¥ '{prefix}' å¼€å¤´çš„ä»£ç æ®µ")
                break
        
        if not should_exclude and block:
            filtered_blocks.append(block)
    
    return filtered_blocks


def save_results(results: dict, output_dir: str):
    """ä¿å­˜æŠ“å–ç»“æœ"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    
    # ä¿å­˜æ±‡æ€»æ–‡ä»¶
    # summary_file = output_path / "bash_codes_summary.md"
    # with open(summary_file, "w", encoding="utf-8") as f:
        # f.write(f"# Wiki Bash ä»£ç æ®µæ±‡æ€»\n\n")
        # f.write(f"**æ›´æ–°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        # f.write("---\n\n")
        
        # for repo, pages in results.items():
            # f.write(f"## ğŸ“¦ {repo}\n\n")
            # for page, codes in pages.items():
                # f.write(f"### ğŸ“„ {page}\n\n")
                # if codes:
                    # for i, code in enumerate(codes, 1):
                        # f.write(f"**ä»£ç æ®µ {i}:**\n\n")
                        # f.write(f"```bash\n{code}\n```\n\n")
                # else:
                    # f.write("*æ²¡æœ‰æ‰¾åˆ° Bash ä»£ç æ®µ*\n\n")
            # f.write("---\n\n")
    
    # print(f"\nâœ“ æ±‡æ€»æ–‡ä»¶å·²ä¿å­˜: {summary_file}")
    
    # ä¿å­˜ JSON æ ¼å¼ï¼ˆä¾¿äºç¨‹åºå¤„ç†ï¼‰
    # json_file = output_path / "bash_codes.json"
    # with open(json_file, "w", encoding="utf-8") as f:
        # json.dump({
            # "updated_at": datetime.now().isoformat(),
            # "data": results
        # }, f, ensure_ascii=False, indent=2)
    
    # print(f"âœ“ JSON æ–‡ä»¶å·²ä¿å­˜: {json_file}")
    
    # ä¿å­˜çº¯ä»£ç æ–‡ä»¶ï¼ˆæ¯ä¸ªä»“åº“ä¸€ä¸ªæ–‡ä»¶ï¼‰
    for repo, pages in results.items():
        repo_filename = repo.replace("/", "_") + "_bash.sh"
        repo_file = output_path / repo_filename
        
        with open(repo_file, "w", encoding="utf-8") as f:
            # f.write(f"#!/bin/bash\n")
            # f.write(f"# Source: {repo}\n")
            # f.write(f"# Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            # f.write(f"# Auto-generated - DO NOT EDIT\n\n")
            
            for page, codes in pages.items():
                if codes:
                    # f.write(f"# === {page} ===\n\n")
                    for code in codes:
                        f.write(f"{code}\n")
        
        print(f"âœ“ ä»“åº“ä»£ç æ–‡ä»¶å·²ä¿å­˜: {repo_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("GitHub Wiki Bash ä»£ç æŠ“å–å™¨")
    print("=" * 50 + "\n")
    
    # åŠ è½½é…ç½®
    config = load_config()
    wiki_pages = config.get("wiki_pages", [])
    exclude_prefixes = config.get("exclude_prefix", ["ssr"])
    output_dir = config.get("output_dir", "output")
    
    # è·å– GitHub Tokenï¼ˆå¯é€‰ï¼Œç”¨äºè®¿é—®ç§æœ‰ä»“åº“ï¼‰
    token = os.environ.get("GITHUB_TOKEN")
    
    print(f"æ’é™¤å‰ç¼€: {exclude_prefixes}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}\n")
    
    results = {}
    
    for wiki_config in wiki_pages:
        repo = wiki_config["repo"]
        pages = wiki_config["pages"]
        
        print(f"\nğŸ“¦ å¤„ç†ä»“åº“: {repo}")
        print("-" * 40)
        
        results[repo] = {}
        
        for page in pages:
            print(f"\n  ğŸ“„ é¡µé¢: {page}")
            
            # è·å– Wiki é¡µé¢å†…å®¹
            content = fetch_wiki_page(repo, page, token)
            
            if content:
                # æå– Bash ä»£ç æ®µ
                bash_codes = extract_bash_code_blocks(content, exclude_prefixes)
                results[repo][page] = bash_codes
                print(f"     æ‰¾åˆ° {len(bash_codes)} ä¸ª Bash ä»£ç æ®µ")
            else:
                results[repo][page] = []
    
    # ä¿å­˜ç»“æœ
    print("\n" + "=" * 50)
    print("ä¿å­˜ç»“æœ")
    print("=" * 50)
    save_results(results, output_dir)
    
    print("\nâœ… å®Œæˆ!")


if __name__ == "__main__":
    main()
